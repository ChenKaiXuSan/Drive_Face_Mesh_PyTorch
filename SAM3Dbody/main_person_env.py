#!/usr/bin/env python3
# -*- coding:utf-8 -*-
"""
File: /workspace/code/SAM3Dbody/main_multi_gpu_process.py
Project: /workspace/code/SAM3Dbody
Created Date: Monday January 26th 2026
Author: Kaixu Chen
-----
Comment:
æ ¹æ®å¤šGPUå¹¶è¡Œå¤„ç†SAM-3D-Bodyæ¨ç†ä»»åŠ¡ã€‚

Have a good code time :)
-----
Last Modified: Monday January 26th 2026 5:12:10 pm
Modified By: the developer formerly known as Kaixu Chen at <chenkaixusan@gmail.com>
-----
Copyright (c) 2026 The University of Tsukuba
-----
HISTORY:
Date      	By	Comments
----------	---	---------------------------------------------------------
"""

import logging
import os
import multiprocessing as mp
from pathlib import Path
from typing import Dict, List
import numpy as np

import hydra
from omegaconf import DictConfig, OmegaConf

# å‡è®¾è¿™äº›æ˜¯ä»ä½ çš„å…¶ä»–æ¨¡å—å¯¼å…¥çš„
from .infer import process_frame_list
from .load import load_data

# --- å¸¸é‡å®šä¹‰ ---
REQUIRED_VIEWS = {"front", "left", "right"}

logger = logging.getLogger(__name__)


# ---------------------------------------------------------------------
# æ ¸å¿ƒå¤„ç†é€»è¾‘ï¼šå¤„ç†å•ä¸ªäººçš„æ•°æ®
# ---------------------------------------------------------------------
def process_single_person_env(
    person_env_dir: Path,
    source_root: Path,
    out_root: Path,
    infer_root: Path,
    cfg: DictConfig,
):
    """å¤„ç†å•ä¸ªäººå‘˜çš„æ‰€æœ‰ç¯å¢ƒå’Œè§†è§’"""
    person_id = person_env_dir.parent.name
    env_name = person_env_dir.name
    vid_patterns = ["*.mp4", "*.mov", "*.avi", "*.mkv", "*.MP4", "*.MOV"]

    # --- 1. Personå°‚ç”¨ã®ãƒ­ã‚°è¨­å®š ---
    log_dir = out_root / "person_logs"
    log_dir.mkdir(parents=True, exist_ok=True)
    person_log_file = log_dir / f"{person_id}_{env_name}.log"

    # æ–°ã—ã„ãƒãƒ³ãƒ‰ãƒ©ã‚’ä½œæˆ
    handler = logging.FileHandler(person_log_file, mode="a", encoding="utf-8")
    formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
    handler.setFormatter(formatter)

    logger = logging.getLogger(f"{person_id}_{env_name}")  # ã“ã®Personå°‚ç”¨ã®ãƒ­ã‚¬ãƒ¼ã‚’å–å¾—
    logger.addHandler(handler)
    # logger.propagate = False  # è¦ªï¼ˆRootï¼‰ãƒ­ã‚¬ãƒ¼ã«ãƒ­ã‚°ã‚’æµã•ãªã„ï¼ˆæ··ã–ã‚‹ã®ã‚’é˜²ãï¼‰

    logger.info(f"==== Starting Process for Person: {person_id}, Env: {env_name} ====")
    rel_env = person_env_dir.relative_to(source_root)

    # --- è§†é¢‘å¤„ç†é€»è¾‘ ---
    view_map: Dict[str, Path] = {}
    for pat in vid_patterns:
        for f in person_env_dir.glob(pat):
            stem = f.stem.lower()
            if stem in REQUIRED_VIEWS:
                view_map[stem] = f.resolve()

    if not all(v in view_map for v in REQUIRED_VIEWS):
        logger.warning(f"[Skip] {rel_env}: è§†è§’ä¸å…¨ {list(view_map.keys())}")

    view_frames: Dict[str, List[np.ndarray]] = load_data(view_map)

    for view, frames in view_frames.items():
        logger.info(f"  è§†è§’ {view} å¤„ç†äº† {len(frames)} å¸§æ•°æ®ã€‚")
        _out_root = out_root / rel_env / view
        _out_root.mkdir(parents=True, exist_ok=True)
        _infer_root = infer_root / rel_env / view
        _infer_root.mkdir(parents=True, exist_ok=True)

        process_frame_list(
            frame_list=frames,
            out_dir=_out_root,
            inference_output_path=_infer_root,
            cfg=cfg,
        )


# ---------------------------------------------------------------------
# GPU Workerï¼šè¿›ç¨‹æ‰§è¡Œå‡½æ•°
# ---------------------------------------------------------------------
def gpu_worker(
    gpu_id: int,
    env_dirs: List[Path],
    source_root: Path,
    out_root: Path,
    infer_root: Path,
    cfg_dict: dict,
):
    """
    æ¯ä¸ªè¿›ç¨‹çš„å…¥å£ï¼šè®¾ç½®ç¯å¢ƒå˜é‡ï¼Œå¹¶å¤„ç†åˆ†é…çš„ä»»åŠ¡åˆ—è¡¨
    """
    # 1. éš”ç¦» GPU
    os.environ["CUDA_VISIBLE_DEVICES"] = str(gpu_id)

    cfg_dict["infer"]["gpu"] = 0  # å› ä¸ºä¸Šé¢å·²ç»éš”ç¦»äº† GPUï¼Œæ‰€ä»¥è¿™é‡Œè®¾ä¸º 0

    # 2. å°†å­—å…¸è½¬å› Hydra é…ç½®ï¼ˆå¤šè¿›ç¨‹ä¼ é€’å¯¹è±¡æ—¶ï¼Œè½¬ä¸ºå­—å…¸æ›´å®‰å…¨ï¼‰
    cfg = OmegaConf.create(cfg_dict)

    logger.info(f"ğŸŸ¢ GPU {gpu_id} è¿›ç¨‹å¯åŠ¨ï¼Œå¾…å¤„ç†ä»»åŠ¡æ•°: {len(env_dirs)}")

    for env_dir in env_dirs:
        try:
            process_single_person_env(env_dir, source_root, out_root, infer_root, cfg)
        except Exception as e:
            logger.error(f"âŒ GPU {gpu_id} å¤„ç† {env_dir.name} æ—¶å‡ºé”™: {e}")

    logger.info(f"ğŸ GPU {gpu_id} æ‰€æœ‰ä»»åŠ¡å¤„ç†å®Œæ¯•")


# ---------------------------------------------------------------------
# Main å…¥å£
# ---------------------------------------------------------------------
@hydra.main(config_path="../configs", config_name="sam3d_body", version_base=None)
def main(cfg: DictConfig) -> None:
    # 1. çµŒè·¯æº–å‚™
    out_root = Path(cfg.paths.log_path).resolve()
    infer_root = Path(cfg.paths.result_output_path).resolve()
    source_root = Path(cfg.paths.video_path).resolve()

    # --- 1. åˆ¶å¾¡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å–å¾— ---
    # cfg.infer.person_list: [1, 2, 3] ã¾ãŸã¯ [-1]
    # cfg.infer.env_list: ["room1", "outdoor"] ã¾ãŸã¯ ["all"]
    target_person_ids = [int(pid) for pid in cfg.infer.get("person_list", [-1])]
    target_envs = cfg.infer.get("env_list", ["all"])

    # --- 2. æ¡ä»¶ã«åˆè‡´ã™ã‚‹ Person/Env ã‚¿ã‚¹ã‚¯ã‚’åé›† ---
    all_env_tasks = []

    # Person ãƒ•ã‚©ãƒ«ãƒ€ã‚’ãƒ«ãƒ¼ãƒ—
    for p_dir in sorted(source_root.iterdir()):
        if not p_dir.is_dir():
            continue

        # Person ID ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        current_p_id = int(p_dir.name)
        if current_p_id in target_person_ids or -1 in target_person_ids:

            # Env ãƒ•ã‚©ãƒ«ãƒ€ã‚’ãƒ«ãƒ¼ãƒ—
            for env_dir in sorted(p_dir.iterdir()):
                if not env_dir.is_dir():
                    continue

                # Env åã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                current_env_name = env_dir.name
                if current_env_name in target_envs or "all" in target_envs:
                    all_env_tasks.append(env_dir)

    if not all_env_tasks:
        logger.error(
            f"æ¡ä»¶ã«åˆã†ã‚¿ã‚¹ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ (Person: {target_person_ids}, Env: {target_envs})"
        )
        return

    # --- 3. ä¸¦åˆ—å‡¦ç†ã®å®Ÿè¡Œ ---
    gpu_ids = cfg.infer.get("gpu", [0, 1])
    workers_per_gpu = cfg.infer.get("workers_per_gpu", 2)

    total_workers = len(gpu_ids) * workers_per_gpu
    chunks = np.array_split(all_env_tasks, total_workers)

    logger.info(f"ä½¿ç”¨ GPU: {gpu_ids} (å„ {workers_per_gpu} ãƒ¯ãƒ¼ã‚«ãƒ¼)")
    logger.info(f"ç·ãƒ—ãƒ­ã‚»ã‚¹æ•°: {total_workers}")
    logger.info(f"ç·å‡¦ç†äººæ•°: {len(target_person_ids)}")

    # 3. å¯åŠ¨å¹¶è¡Œè¿›ç¨‹
    cfg_dict = OmegaConf.to_container(cfg, resolve=True)
    mp.set_start_method("spawn", force=True)

    processes = []
    for i, gpu_id in enumerate(np.repeat(gpu_ids, workers_per_gpu)):
        env_list = chunks[i].tolist()
        if not env_list:
            continue

        logger.info(f"  - Worker {i} (GPU {gpu_id}) åˆ†é…ä»»åŠ¡æ•°: {len(env_list)}")

        p = mp.Process(
            target=gpu_worker,
            args=(
                gpu_id,
                env_list,
                source_root,
                out_root,
                infer_root,
                cfg_dict,
            ),
        )
        p.start()
        processes.append(p)

    # 4. ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
    for p in processes:
        p.join()

    logger.info("ğŸ‰ [SUCCESS] æ‰€æœ‰ GPU ä»»åŠ¡å·²åœ†æ»¡å®Œæˆï¼")


if __name__ == "__main__":
    os.environ["HYDRA_FULL_ERROR"] = "1"
    main()
