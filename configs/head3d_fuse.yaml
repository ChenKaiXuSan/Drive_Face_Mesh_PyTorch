# hydra config
hydra:
  run:
    dir: ${log_path}
  job:
    chdir: false

# Path
paths:
  video_path: /workspace/data/videos_split
  result_output_path: /workspace/data/head3d_fuse_results
  sam3d_results_path: /workspace/data/sam3d_body_results_right
  start_mid_end_path: /workspace/data/annotation/split_mid_end/mini.json # 我们不需要推导左右的frame，按照这里面的start和mid来进行推导

log_path: logs/head3d_fuse/${now:%Y-%m-%d}/${now:%H-%M-%S}

visualize:
  save_mesh_ply: false
  save_mesh_overlay: false
  save_bbox_image: false
  save_3d_mesh: false
  save_3d_keypoints: true

infer:
  num_inference_steps: 4
  view_list: [front, left, right]

  workers: 32
  person_list: [-1] # 指定需要处理的人物 ID 列表，-1 表示处理所有人物
  env_list: [all] # 指定需要处理的环境 ID 列表，-1 表示处理所有环境

fuse:
  fuse_method: median
  # Optional: align per-view 3D outputs into a common world coordinate before fusing.
  # Each view can specify R (3x3) and t (3,) from camera to world (or world to camera).
  # transform_mode: world_to_camera uses X_world = (X_cam - t_wc) @ R,
  # where C = -(t_wc @ R). If providing C or t instead, X_world = X_cam @ R + C.
  # transform_mode: camera_to_world uses X_world = X_cam @ R.T + t (camera origin in world).
  transform_mode: world_to_camera
  view_transforms: {}

  # When extrinsics are unavailable, align each view to a reference with Procrustes.
  # alignment_method: none | procrustes | procrustes_trimmed
  # alignment_reference: view name to align others against (null uses first view)
  alignment_method: none
  alignment_reference: null
  alignment_scale: true
  alignment_trim_ratio: 0.2
  alignment_max_iters: 3

  # ========== 融合结果与单视角对比评估配置 ==========
  # 启用融合结果与单视角的对比评估
  enable_fused_view_comparison: true
  
  # 要评估的关键点索引（默认评估前7个关键点：鼻子、眼睛、耳朵、肩膀）
  # 0: nose, 1: left-eye, 2: right-eye, 3: left-ear, 4: right-ear
  # 5: left-shoulder, 6: right-shoulder
  fused_view_comparison_keypoint_indices: [0, 1, 2, 3, 4, 5, 6]
  
  # 是否生成可视化图表
  enable_fused_view_comparison_plots: true

  
# ========== 时间平滑配置 ==========
smooth:
  
  # 是否启用时间平滑（默认关闭）
  enable_temporal_smooth: true
  
  # 平滑方法选择: "gaussian", "savgol", "kalman", "bilateral"
  temporal_smooth_method: "gaussian"
  
  # ===== 方法1: Gaussian 平滑参数 =====
  # 当 temporal_smooth_method: "gaussian" 时使用
  temporal_smooth_sigma: 1.5  # 标准差，越大越平滑。推荐: 1.0-2.0
  
  # ===== 方法2: Savitzky-Golay 滤波参数 =====
  # 当 temporal_smooth_method: "savgol" 时使用
  # temporal_smooth_window_length: 11  # 窗口大小（必须是奇数），推荐: 7, 11, 15
  # temporal_smooth_polyorder: 3       # 多项式阶数，推荐: 2-4
  
  # ===== 方法3: Kalman 滤波参数 =====
  # 当 temporal_smooth_method: "kalman" 时使用
  # temporal_smooth_process_variance: 1.0e-5      # 过程噪声方差
  # temporal_smooth_measurement_variance: 1.0e-2  # 测量噪声方差
  
  # ===== 方法4: Bilateral 滤波参数 =====
  # 当 temporal_smooth_method: "bilateral" 时使用
  # temporal_smooth_sigma_space: 1.5  # 时间域标准差
  # temporal_smooth_sigma_range: 0.1  # 值域标准差
  
  # ========== 平滑效果比较配置 ==========
  
  # 是否启用比较（生成报告和图表）
  enable_comparison: true
  
  # 是否生成可视化图表
  enable_comparison_plots: true
  
  # 要在轨迹图中显示的关键点索引
  comparison_keypoint_indices: [0, 1, 2, 3, 4, 5, 6]  # 头部，肩膀


# ========================================
# 不同场景的推荐配置
# ========================================

# 场景1: 快速处理，轻度平滑
# infer:
#   enable_temporal_smooth: true
#   temporal_smooth_method: "gaussian"
#   temporal_smooth_sigma: 1.0

# 场景2: 保留快速动作细节
# infer:
#   enable_temporal_smooth: true
#   temporal_smooth_method: "savgol"
#   temporal_smooth_window_length: 7
#   temporal_smooth_polyorder: 2

# 场景3: 较强平滑，适合噪声大的数据
# infer:
#   enable_temporal_smooth: true
#   temporal_smooth_method: "gaussian"
#   temporal_smooth_sigma: 2.5

# 场景4: 规律运动，使用卡尔曼滤波
# infer:
#   enable_temporal_smooth: true
#   temporal_smooth_method: "kalman"
#   temporal_smooth_process_variance: 1.0e-5
#   temporal_smooth_measurement_variance: 1.0e-2

# 场景5: 保留运动边界（如快速手势变化）
# infer:
#   enable_temporal_smooth: true
#   temporal_smooth_method: "bilateral"
#   temporal_smooth_sigma_space: 1.5
#   temporal_smooth_sigma_range: 0.1

# ========================================
# 融合结果与单视角对比评估说明
# ========================================

# 此功能用于评估融合后的3D关键点与各个单视角3D关键点的质量差异
# 
# 输出结果：
# <out_root>/<person_id>/<env_name>/fused_vs_views_comparison/
#   ├── fused_vs_views_metrics.json        # JSON格式的所有指标
#   ├── fused_vs_views_report.txt          # 详细的文本报告
#   └── fused_vs_views_comparison.png      # 可视化对比图表（6张子图）
#
# 评估指标：
# 1. 融合结果与各视角的平均距离（越小越接近该视角）
# 2. 融合结果与视角质心的距离（越小说明融合越居中）
# 3. 时间稳定性对比（Jitter = 加速度，越小越稳定）
# 4. 视角间一致性（两两视角的差异，越小说明原始数据越一致）
# 5. 各关键点与视角的详细分析
#
# 理想的融合结果应该：
# - 与质心距离小（融合结果居中，没有偏向某个视角）
# - Jitter 小于单视角（融合带来了时间平滑效果）
# - 与各视角距离相近（融合考虑了所有视角）
#
# 使用方法：
# 1. 设置 enable_fused_view_comparison: true 启用评估
# 2. 配置 fused_view_comparison_keypoint_indices 选择要评估的关键点
# 3. 设置 enable_fused_view_comparison_plots: true 生成可视化图表
#
# 详细文档：doc/FUSED_VIEW_COMPARISON_GUIDE.md
